{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce0f11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Scikit-Learn ≥0.20\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from zlib import crc32\n",
    "import hashlib\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from six.moves import urllib\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import (TimeSeriesSplit, KFold, ShuffleSplit,\n",
    "StratifiedKFold, GroupShuffleSplit,\n",
    "GroupKFold, StratifiedShuffleSplit,cross_val_score)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import (StandardScaler, PolynomialFeatures)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (OrdinalEncoder,OneHotEncoder)\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-poster')\n",
    "from ta.utils import dropna\n",
    "from ta.volatility import BollingerBands\n",
    "from ta import add_all_ta_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "\n",
    "import settings\n",
    "from ta import *\n",
    "import utils\n",
    "\n",
    "import datetime, pytz\n",
    "#define a conversion function for the native timestamps in the csv file\n",
    "def dateparse (time_in_secs):    \n",
    "    return pytz.utc.localize(datetime.datetime.fromtimestamp(float(time_in_secs)))\n",
    "\n",
    "# Donde guardar las figuras\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861efe6c",
   "metadata": {},
   "source": [
    "# Split train - test (XGBoost, esto podria ir aparte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018bab2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "82b0a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_hist = pd.read_csv(\"processed_data/processed_bitcoin_history.csv\")\n",
    "df = bitcoin_hist.drop('Timestamp',axis=1)\n",
    "# df = df.drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0068d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = utils.split_df2(df)\n",
    "excl = ['Close_target', 'Target', 'Date', 'Timestamp']\n",
    "cols = [c for c in df.columns if c not in excl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c95edd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:11:52] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"n_trees\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:11:52] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"n_trees\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:11:52] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"n_trees\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "705\n",
      "[20:11:55] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"n_trees\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Accuracy: 0.9952907082050353\n",
      "Coefficient Kappa: 0.9905813926174695\n",
      "Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 2, does not match size of target_names, 3. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-d55bd80ec0c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n \\n \\n \\n \\n \\n ********** WEIGHT ************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UBA/Aprendizaje Automático/aa-tp-crypto/utils.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(y_true, y_pred, y_pred_proba)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Coefficient Kappa: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcohen_kappa_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Classification Report:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Confussion Matrix:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1989\u001b[0m             )\n\u001b[1;32m   1990\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1992\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 2, does not match size of target_names, 3. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "y_train = train['Target']\n",
    "y_mean = np.mean(y_train)\n",
    "xgb_params = {\n",
    "    'n_trees': 800,\n",
    "    'eta': 0.0045,\n",
    "    'max_depth': 20,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.95,\n",
    "    'colsample_bylevel': 0.95,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class' : 3,\n",
    "    'eval_metric': 'mlogloss', # 'merror', # 'rmse',\n",
    "    'base_score': 0,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(train[cols], y_train)\n",
    "dtest = xgb.DMatrix(test[cols])\n",
    "\n",
    "cv_result = xgb.cv(xgb_params, dtrain)\n",
    "\n",
    "# xgboost, cross-validation\n",
    "\"\"\"\n",
    "cv_result = xgb.cv(xgb_params,\n",
    "                   dtrain,\n",
    "                   num_boost_round=5000,\n",
    "                   early_stopping_rounds=50,\n",
    "                   verbose_eval=50,\n",
    "                   show_stdv=False\n",
    "                  )\n",
    "num_boost_rounds = len(cv_result)\n",
    "\"\"\"\n",
    "num_boost_rounds = 705\n",
    "\n",
    "print(num_boost_rounds)\n",
    "\n",
    "# train\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "# predict\n",
    "y_pred = model.predict(dtest)\n",
    "y_true = test['Target']\n",
    "\n",
    "utils.metrics(y_true, y_pred)\n",
    "\n",
    "print(\"\\n \\n \\n \\n \\n \\n ********** WEIGHT ************\")\n",
    "importance = model.get_fscore()\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "for i in importance:\n",
    "    print (i)\n",
    "    \n",
    "print(\"\\n \\n \\n \\n \\n \\n ********** GAIN ************\")\n",
    "importance = model.get_score(fmap='', importance_type='gain')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "for i in importance:\n",
    "    print (i)\n",
    "    \n",
    "print(\"\\n \\n \\n \\n \\n \\n ********** COVER ************\")\n",
    "importance = model.get_score(fmap='', importance_type='cover')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "for i in importance:\n",
    "    print (i)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
